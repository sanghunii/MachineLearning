{"cells":[{"cell_type":"code","execution_count":1,"id":"3f04e626","metadata":{"id":"3f04e626","executionInfo":{"status":"error","timestamp":1717855941329,"user_tz":-540,"elapsed":2334,"user":{"displayName":"박상훈","userId":"15184972261379175724"}},"outputId":"f86b6413-43a3-4417-cb22-4d9f590b95d5","colab":{"base_uri":"https://localhost:8080/","height":306}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["0.773109243697479\n","0.775\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'np' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-8ae1a2a7ad63>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#Stochastic Gradient Descent can incremetnal learning by using partial_fit() method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#By this method, without creating a new training object, can continue learning from existing objects one epoch at a time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m#different output from book\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}],"source":["import pandas as pd\n","fish = pd.read_csv('https://bit.ly/fish_csv_data')\n","\n","fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy()\n","fish_target = fish['Species'].to_numpy()\n","#print(pd.unique(fish['Species'])) #Check there is how many and what kind of classes existing.\n","\n","from sklearn.model_selection import train_test_split\n","train_input, test_input, train_target, test_target = train_test_split(fish_input, fish_target, random_state = 42)\n","\n","from sklearn.preprocessing import StandardScaler\n","ss = StandardScaler()\n","ss.fit(train_input)\n","train_scaled = ss.transform(train_input)\n","test_scaled = ss.transform(test_input)\n","\n","from sklearn.linear_model import SGDClassifier\n","sc = SGDClassifier(loss = 'log_loss', max_iter = 10, random_state = 42)\n","sc.fit(train_scaled, train_target)\n","print(sc.score(train_scaled, train_target))  #different output from book\n","print(sc.score(test_scaled, test_target))    #different output from book\n","\n","#Stochastic Gradient Descent can incremetnal learning by using partial_fit() method\n","#By this method, without creating a new training object, can continue learning from existing objects one epoch at a time.\n","classes = np.unique(train_target)\n","sc.partial_fit(train_scaled, train_target)\n","print(sc.score(train_scaled, train_target))    #different output from book\n","print(sc.score(test_scaled, test_target))      #different output from book\n","\n","\n","#Early stopping\n","#It is technique of prevent over/under fitting\n","import numpy as np\n","sc = SGDClassifier(loss = 'log_loss', random_state = 42)\n","train_score = []\n","test_score = []\n","classes = np.unique(train_target)\n","\n","#_ is special variance\n","#This is used to temporarily store unused values.\n","for _ in range(0, 300):\n","    sc.partial_fit(train_scaled, train_target, classes = classes)\n","    train_score.append(sc.score(train_scaled, train_target))\n","    test_score.append(sc.score(test_scaled, test_target))\n","\n","import matplotlib.pyplot as plt\n","plt.plot(train_score)\n","plt.plot(test_score)\n","plt.xlabel('epoch')\n","plt.ylabel('accuracy')\n","plt.show()\n","\n","#tol parameter is control tolerance(허용오차).\n","sc = SGDClassifier(loss= 'log_loss', max_iter = 75, tol = None, random_state = 42)\n","sc.fit(train_scaled, train_target)\n","print(sc.score(train_scaled, train_target))\n","print(sc.score(test_scaled, test_target))"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}